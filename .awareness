{
    "clusters": [
        {
            "name": "openai.com",
            "models": [
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "best",
                    "model": "gpt-4o",
                    "tokenizer": "clk100",
                    "max_input_tokens": 24000,
                    "max_tokens": 4000,
                    "seed": 100,
                    "tags": []
                },
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "gpt-4o",
                    "model": "gpt-4o",
                    "tokenizer": "clk100",
                    "max_input_tokens": 6000,
                    "max_tokens": 1500,
                    "seed": 100,
                    "tags": []
                },
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "gpt-4o:max",
                    "model": "gpt-4o",
                    "tokenizer": "clk100",
                    "max_input_tokens": 120000,
                    "max_tokens": 4000,
                    "seed": 100,
                    "tags": []
                },
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "gpt-3.5",
                    "model": "gpt-3.5-turbo-16k",
                    "tokenizer": "clk100",
                    "max_input_tokens": 6000,
                    "max_tokens": 1500,
                    "seed": 100,
                    "tags": []
                },
                {
                    "type": "embeddings",
                    "client": "openai",
                    "alias": "text-embedding-ada-002",
                    "model": "text-embedding-ada-002",
                    "tokenizer": "clk100",
                    "max_input_tokens": 8000
                },
                {
                    "type": "embeddings",
                    "client": "openai",
                    "alias": "text-embedding-3-small",
                    "model": "text-embedding-3-small",
                    "tokenizer": "clk100",
                    "max_input_tokens": 8000,
                    "dimensions": 512
                },
                {
                    "type": "embeddings",
                    "client": "openai",
                    "alias": "text-embedding-3-large",
                    "model": "text-embedding-3-large",
                    "tokenizer": "clk100",
                    "max_input_tokens": 8000,
                    "dimensions": 256
                }
            ],
            "endpoints": [
                {
                    "url": "https://api.openai.com",
                    "concurrency": 4
                }
            ],
            "logRequests": false
        },
        {
            "name": "fireworks.ai",
            "models": [
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "good",
                    "model": "accounts/fireworks/models/mixtral-8x7b-instruct",
                    "tokenizer": "llama",
                    "max_input_tokens": 24000,
                    "max_tokens": 4000,
                    "stop": ["\n<QUESTION>", "\n<INSTRUCTIONS>", "\n<FACTS>"]
                },
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "better",
                    "model": "accounts/fireworks/models/mixtral-8x22b-instruct",
                    "tokenizer": "llama",
                    "max_input_tokens": 24000,
                    "max_tokens": 4000,
                    "stop": ["\n<QUESTION>", "\n<INSTRUCTIONS>", "\n<FACTS>"]
                },
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "better:long",
                    "model": "accounts/fireworks/models/mixtral-8x22b-instruct",
                    "tokenizer": "llama",
                    "max_input_tokens": 48000,
                    "max_tokens": 12000,
                    "stop": ["\n<QUESTION>", "\n<INSTRUCTIONS>", "\n<FACTS>"]
                },
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "llama-3-70b-instruct",
                    "model": "accounts/fireworks/models/llama-v3-70b-instruct",
                    "tokenizer": "llama",
                    "max_input_tokens": 6000,
                    "max_tokens": 1500,
                    "stop": ["\n<QUESTION>", "\n<INSTRUCTIONS>", "\n<FACTS>"],
                    "tags": ["repairable"]
                },
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "synapse-medium",
                    "model": "accounts/fireworks/models/llama-v3-70b-instruct",
                    "tokenizer": "llama",
                    "max_input_tokens": 6000,
                    "max_tokens": 1500,
                    "stop": ["\n<QUESTION>", "\n<INSTRUCTIONS>", "\n<FACTS>"],
                    "tags": ["repairable"]
                }
            ],
            "endpoints": [
                {
                    "url": "https://api.fireworks.ai/inference",
                    "concurrency": 12
                }
            ],
            "logRequests": false
        },
        {
            "name": "google.com",
            "models": [
                {
                    "type": "chat",
                    "client": "google",
                    "alias": "gemini-pro",
                    "model": "gemini-1.5-pro-latest",
                    "tokenizer": "google",
                    "max_input_tokens": 24000,
                    "max_tokens": 4000,
                    "stop": ["\n<QUESTION>", "\n<INSTRUCTIONS>", "\n<FACTS>"],
                    "tags": ["repairable"]
                },
                {
                    "type": "chat",
                    "client": "google",
                    "alias": "gemini-pro:max",
                    "model": "gemini-1.5-pro-latest",
                    "tokenizer": "google",
                    "max_input_tokens": 120000,
                    "max_tokens": 8000,
                    "stop": ["\n<QUESTION>", "\n<INSTRUCTIONS>", "\n<FACTS>"],
                    "tags": ["repairable"]
                }
            ],
            "endpoints": [
                {
                    "url": "https://generativelanguage.googleapis.com",
                    "concurrency": 1
                }
            ],
            "logRequests": false
        },
        {
            "name": "groq.com",
            "models": [
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "groq-llama-3-70b",
                    "model": "llama3-70b-8192",
                    "tokenizer": "llama",
                    "max_input_tokens": 6000,
                    "max_tokens": 1500,
                    "seed": 100,
                    "stop": ["\n<QUESTION>", "\n<INSTRUCTIONS>", "\n<FACTS>"]
                }
            ],
            "endpoints": [
                {
                    "url": "https://api.groq.com/openai",
                    "concurrency": 1
                }
            ],
            "logRequests": false,
            "requestDelay": 30000
        },
        {
            "name": "anthropic.com",
            "models": [
                {
                    "type": "chat",
                    "client": "anthropic",
                    "alias": "sonnet",
                    "model": "claude-3-5-sonnet-20240620",
                    "tokenizer": "claude",
                    "max_input_tokens": 24000,
                    "max_tokens": 4000
                }
            ],
            "endpoints": [
                {
                    "url": "https://api.anthropic.com",
                    "concurrency": 4
                }
            ],
            "logRequests": false
        },
        {
            "name": "deepseek.com",
            "models": [
                {
                    "type": "chat",
                    "client": "oss",
                    "alias": "coding",
                    "model": "deepseek-coder",
                    "tokenizer": "llama",
                    "max_input_tokens": 24000,
                    "max_tokens": 4000,
                    "top_p": 1.0
                }
            ],
            "endpoints": [
                {
                    "url": "https://api.deepseek.com",
                    "concurrency": 4
                }
            ],
            "logRequests": false
        },
        {
            "name": "ARC-4090",
            "models": [
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "arc",
                    "model": "synapse-small",
                    "tokenizer": "llama",
                    "max_input_tokens": 6000,
                    "max_tokens": 1500,
                    "seed": 100,
                    "tags": []
                }
            ],
            "endpoints": [
                {
                    "url": "http://api.awarity.ai:8080",
                    "concurrency": 1,
                    "apiKey": "EMPTY"
                },
                {
                    "url": "http://api.awarity.ai:8081",
                    "concurrency": 1,
                    "apiKey": "EMPTY"
                },
                {
                    "url": "http://api.awarity.ai:8082",
                    "concurrency": 1,
                    "apiKey": "EMPTY"
                },
                {
                    "url": "http://api.awarity.ai:8083",
                    "concurrency": 1,
                    "apiKey": "EMPTY"
                }
            ],
            "logRequests": false
        }
    ],
    "defaultEmbeddings": "text-embedding-3-small",
    "defaultModel": "better"
}