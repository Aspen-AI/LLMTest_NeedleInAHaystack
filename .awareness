{
    "clusters": [
        {
            "name": "openai.com",
            "type": "OpenAI",
            "models": [
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "gpt-3.5",
                    "model": "gpt-3.5-turbo-16k",
                    "tokenizer": "clk100",
                    "max_input_tokens": 6000,
                    "max_tokens": 1500,
                    "seed": 100,
                    "tags": ["repairable"]
                },
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "gpt-4",
                    "model": "gpt-4o",
                    "tokenizer": "clk100",
                    "max_input_tokens": 6000,
                    "max_tokens": 1500,
                    "seed": 100,
                    "tags": ["repairable"]
                },
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "gpt-4-medium",
                    "model": "gpt-4o",
                    "tokenizer": "clk100",
                    "max_input_tokens": 24000,
                    "max_tokens": 4000,
                    "seed": 100,
                    "tags": ["repairable"]
                },
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "gpt-4-large",
                    "model": "gpt-4o",
                    "tokenizer": "clk100",
                    "max_input_tokens": 60000,
                    "max_tokens": 20000,
                    "seed": 100,
                    "tags": ["repairable"]
                },
                {
                    "type": "embeddings",
                    "client": "openai",
                    "alias": "text-embedding-ada-002",
                    "model": "text-embedding-ada-002",
                    "tokenizer": "clk100",
                    "max_input_tokens": 8000
                },
                {
                    "type": "embeddings",
                    "client": "openai",
                    "alias": "text-embedding-3-small",
                    "model": "text-embedding-3-small",
                    "tokenizer": "clk100",
                    "max_input_tokens": 8000,
                    "dimensions": 512
                },
                {
                    "type": "embeddings",
                    "client": "openai",
                    "alias": "text-embedding-3-large",
                    "model": "text-embedding-3-large",
                    "tokenizer": "clk100",
                    "max_input_tokens": 8000,
                    "dimensions": 256
                }
            ],
            "endpoints": [
                {
                    "url": "https://api.openai.com",
                    "concurrency": 4
                }
            ],
            "logRequests": false
        },
        {
            "name": "fireworks.ai",
            "type": "OpenAI",
            "models": [
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "synapse-medium",
                    "model": "accounts/fireworks/models/llama-v3-70b-instruct",
                    "tokenizer": "llama",
                    "max_input_tokens": 6000,
                    "max_tokens": 1500,
                    "stop": ["\n<QUESTION>", "\n<INSTRUCTIONS>", "\n<FACTS>"],
                    "tags": ["repairable"]
                }
            ],
            "endpoints": [
                {
                    "url": "https://api.fireworks.ai/inference",
                    "concurrency": 4
                }
            ],
            "logRequests": false
        },
        {
            "name": "groq.com",
            "type": "OpenAI",
            "models": [
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "groq-llama-3-8b",
                    "model": "llama3-8b-8192",
                    "tokenizer": "llama",
                    "max_input_tokens": 6000,
                    "max_tokens": 1500,
                    "seed": 100,
                    "stop": ["\n<QUESTION>", "\n<INSTRUCTIONS>", "\n<FACTS>"],
                    "tags": ["repairable"]
                },
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "groq-llama-3-70b",
                    "model": "llama3-70b-8192",
                    "tokenizer": "llama",
                    "max_input_tokens": 6000,
                    "max_tokens": 1500,
                    "seed": 100,
                    "stop": ["\n<QUESTION>", "\n<INSTRUCTIONS>", "\n<FACTS>"],
                    "tags": ["repairable"]
                },
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "groq-mixtral-8x7b",
                    "model": "mixtral-8x7b-32768",
                    "tokenizer": "mistral",
                    "max_input_tokens": 6000,
                    "max_tokens": 1500,
                    "seed": 100,
                    "stop": ["\n<QUESTION>", "\n<INSTRUCTIONS>", "\n<FACTS>"],
                    "tags": ["repairable"]
                }
            ],
            "endpoints": [
                {
                    "url": "https://api.groq.com/openai",
                    "concurrency": 1
                }
            ],
            "logRequests": false,
            "requestDelay": 30000
        },
        {
            "name": "ARC-4090",
            "type": "OpenAI",
            "models": [
                {
                    "type": "chat",
                    "client": "openai",
                    "alias": "synapse-small",
                    "model": "synapse-small",
                    "tokenizer": "llama",
                    "max_input_tokens": 6000,
                    "max_tokens": 1500,
                    "seed": 100,
                    "tags": []
                }
            ],
            "endpoints": [
                {
                    "url": "http://api.awarity.ai:8080",
                    "concurrency": 1,
                    "apiKey": "EMPTY"
                },
                {
                    "url": "http://api.awarity.ai:8081",
                    "concurrency": 1,
                    "apiKey": "EMPTY"
                },
                {
                    "url": "http://api.awarity.ai:8082",
                    "concurrency": 1,
                    "apiKey": "EMPTY"
                },
                {
                    "url": "http://api.awarity.ai:8083",
                    "concurrency": 1,
                    "apiKey": "EMPTY"
                }
            ],
            "logRequests": false
        }
    ],
    "defaultEmbeddings": "text-embedding-3-small",
    "defaultModel": "gpt-4"
}